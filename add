#!/usr/bin/env ruby
require "net/http"
require "uri"
require "skrape"
require "json"
require "string_processing"
require "slop"
require "geocoder"

class Hash
  def to_graphql
    # self.reduce("{}"){|acc,v| acc == "{}" ? acc.insert(-2, "#{v[0]}: #{v[1]}") : acc.insert(-2, ", #{v[0]}: #{v[1]}")}
    # self.reduce("{}"){|acc,v| v[1] = "\"\"".insert(-2, v[1]) if v[1].is_a? String ; acc == "{}" ? acc.insert(-2, "#{v[0    ]}: #{v[1]}") : acc.insert(-2, ", #{v[0]}: #{v[1]}")}
    self.reduce("{}"){|acc,v| acc == "{}" ? acc.insert(-2, "#{v[0]}: #{v[1].is_a?(String) ? "\"#{v[1]}\"" : v[1]}") : acc.insert(-2, ", #{v[0]}: #{v[1].is_a?(String) ? "\"#{v[1]}\"" : v[1]}")}
  end
end

class GraphQLServer
  def initialize(url = "http://www.usesth.is/graphql")
    @uri = URI.parse(url)
    @header = {'Content-Type': 'application/graphql; charset=utf-8'}
  end

  def query query
    send_request query
  end

  def mutate mutation
    send_request mutation
  end

  def send_request(gql)
    http = Net::HTTP.new(@uri.host, @uri.port)
    request = Net::HTTP::Post.new(@uri.request_uri, @header)
    request.body = gql
    response = http.request(request)
    response.body
  end
end


TagNormalizer = StringProcessing::Pipeline.define do
  using proc{|x| x.map{|n| n.gsub(/mongo( db|-db)/, 'mongodb') }}
  using proc{|x| x.map{|n| n.gsub(/\Arails( \d.+|\z)/, 'ruby-on-rails')}}
  using proc{|x| x.map{|n| n.gsub(/(\s|-)\d.+\z/, '')}}
  using proc{|x| x.map{|n| n.gsub(/\Aangular\z/, 'angular.js') }}
  using proc{|x| x.map{|n| n.gsub(/(\.|\s?|-?)js/, '.js') }}
  using proc{|x| x.map{|n| n.gsub(/\Aoracle\d+\S\z/, 'oracle') }}
  using proc{|x| x.map{|n| n.gsub(/#\z/, '-sharp') }}
  using proc{|x| x.map{|n| n.split(' and ') } }
  using proc{|x| x.map{|n| n.split('&') } }
  using proc{|x| x.map{|n| n.split('/') } }
  using proc{|x| x.map(&:downcase) }
  using proc{|x| x.map(&:strip) }
  using proc{|x| x.map{|n| n.gsub(/\b\s\b/, '-') }}
  using proc{|x| x.reject{|n| n.match /{{.+}}/ }}
  using proc{|x| x.reject{|n| n == "api" }}
  using proc{|x| x.reject{|n| n == "sysadmin" }}
  using proc{|x| x.reject{|n| n == "oop" }}
  using proc{|x| x.reject{|n| n == "engineer" }}
  using proc{|x| x.reject{|n| n == "rdbms" }}
  using proc{|x| x.reject{|n| n == "sdlc" }}
  using proc{|x| x.reject{|n| n == "personalization" }}
  using proc{|x| x.reject{|n| n == "usability" }}
  using proc{|x| x.reject{|n| n == "communications" }}
  using proc{|x| x.reject{|n| n == "user-experience" }}
  using proc{|x| x.uniq }
end

opts = Slop.new(strict: true, help: true) do
  banner 'Usage: add [options]'

  on 'u=', :url=, 'the url of the page to scrape', required: true
end

begin
  opts.parse

  organization = {}

  hostname = URI(opts[:url]).hostname

  organization[:locations] = []

  raise "This only works with Stackoverflow at the moment" unless hostname == "careers.stackoverflow.com"

  raw_results = Skrape::Page.new(opts[:url]).extract do
    extract_locations with: '.address', and_run: proc {|address| address.map{|a| a.inner_html.gsub('<br>', ', ')} }
    extract_technology_list with: "[class~='post-tag']", and_run: proc { |tags|
      tags.map{|tag| tag.text}.join(', ')
    }
    extract_name with: "[data-company-section='company-info'] h1", and_run: proc { |name|
      name.text.capitalize
    }
    extract_url with: "[class~='up-and-out']", and_run: proc {|url| url.attr('href').value }
    extract_founding_year with: "li.founded", and_run: proc {|tds| tds.last ? tds.last.text[/(\d{4})/] : nil }
  end

  raise StandardError 'No technologies were listed!' if raw_results[:technology_list].empty?

  organization[:name] = raw_results[:name]
  organization[:url] = raw_results[:url]
  organization[:founding_year] = raw_results[:founding_year]


  raw_results[:locations].each do |loc|

    geo_result = Geocoder.search(loc)

    location = {}
    if geo_result == [] || geo_result.first.precision == "APPROXIMATE"
      puts "XXX Could only find approximate results for this address:"
      puts "---> #{loc}"
      puts '1) enter a corrected address'
      puts '2) enter a comma separated lat,lng'
      choice = STDIN.gets.strip
      if choice.to_i == 1
        puts "Enter a corrected address: "
        address = STDIN.gets.strip
        location[:lat], location[:lng] = Geocoder.search(address).first.coordinates
        location[:address] = address
      elsif choice.to_i == 2
        puts "Enter a comma separated lat/lng: "
        location[:lat], location[:lng] = STDIN.gets.strip.split(',')
        location[:address] = loc
      end
    else
      location[:lat], location[:lng] = geo_result.first.coordinates
      location[:address] = geo_result.first.formatted_address
    end

    organization[:locations] << location
  end

  tags = TagNormalizer.process(raw_results[:technology_list].split(','))

  organization[:technologies] = tags.map{|tag| {name: tag}}

  puts organization

  # XXX: category is required but the values are unknown to the user.
  # Add Enum type and try again.
  graphql_mutation = <<-GRAPHQL
      mutation { createOrganization(
        name: "#{organization[:name]}"
#{ "      founding_year: " + organization[:founding_year] if organization[:founding_year]}
        url: "#{organization[:url]}"
        locations: [#{organization[:locations].map(&:to_graphql).join(", ")}]
        technologies: [#{organization[:technologies].map(&:to_graphql).join(", ")}]
      ) {
        name
        founding_year
        url
      }
    }
  GRAPHQL
  puts graphql_mutation

  server = GraphQLServer.new("http://localhost:3000/graphql")
  response = server.mutate graphql_mutation
  puts response


rescue Slop::Error => e
  puts e.message
  puts opts
end


